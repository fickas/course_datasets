{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2ltlKvfglIC9M27Kujy4K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fickas/course_datasets/blob/main/good_ai_gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "<h1>Test of Gemini for AI for Good course</h1>\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "iwO77qk8g49x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Custom library for the course\n",
        "\n",
        "I wrote a library that students load at the top of every notebook chapter. I had three goals:\n",
        "\n",
        "1. Hide OOP and in particular, methods. Make everything function-based. I did not do away with OOP given we still use pandas dataframes. But pandas methods get wrapped in puddles functions. All puddles function names have prefix `up_`.\n",
        "\n",
        "2. Hide lazy evaluation, in particular with zip and range.\n",
        "\n",
        "3. Hide complicated code/libraries, e.g., matplotlib, building a NN from tensorflow/keras primitives. This is now hidden behind a puddles function."
      ],
      "metadata": {
        "id": "2s84_20LrWW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install uo-puddles\n",
        "from uo_puddles.good_ai import *"
      ],
      "metadata": {
        "id": "gadqYhzliTMy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Original intent\n",
        "\n",
        "I wrote the library to allow me to get into challenging topics with a basic understanding of Python. And I admit I was lazy with documentation: no doc strings, few type-hints.\n",
        "\n",
        "However, this laziness now helps me spot when a \"co-pilot\" is being used! co-pilots do not seem to do well with my library code without documentation. So even if I ask them to use puddles when appropriate, they often screw up. That seems to change once I add full documentation. I'll demo later."
      ],
      "metadata": {
        "id": "j8_afa10szj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Use of Gemini\n",
        "\n",
        "I do show students how to turn it on and off.\n",
        "\n",
        "I do not model its use specifically. In particular, I never demo how you can ask for full answers.\n",
        "\n",
        "However, I do leave it on for code completion. So students see it in action."
      ],
      "metadata": {
        "id": "tRZmcIHuD4fv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Challenge 1\n",
        "\n",
        "Assume you have two lists of binary values. The first we will call the true labels. The second the predicted labels. Write a function `compute_metrics` that returns the following values: Precision, Recall, F1.\n",
        "\n",
        "You might consider zipping up the lists, your choice."
      ],
      "metadata": {
        "id": "-gdP3v8Cg-st"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Here is a test (most of this code auto-generated)"
      ],
      "metadata": {
        "id": "fREGuwKZnRv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = [1, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
        "predicted_labels = [1, 1, 1, 0, 0, 1, 1, 0, 0, 0]\n",
        "p,r,f1 = compute_metrics(true_labels, predicted_labels)\n",
        "print(p,r,f1)  #0.6 0.6 0.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmE14eeynZQf",
        "outputId": "f416410e-4f82-4a27-a163-56c7d4acd4ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6 0.6 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Difficult decision\n",
        "\n",
        "It is clear that most if not all of the code written by Gemini. I do introduce list-comprehensions but stay away from filtered versions. I only use ternary conditionals and stay away from if-then-else. I do not model doc-strings. I do not use zip but instead a puddles function up_zip.\n",
        "\n",
        "Even though the function is correct, I would typically ask them to rewrite most of the code using only what they have seen in class.\n",
        "\n",
        "From these students I do not get push back, although I could see it happening in a CS class: \"It's correct so why do I have to rewrite it?\""
      ],
      "metadata": {
        "id": "krSwlZwxozc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###I'll ask Claude to rewrite it\n",
        "\n",
        "Given my feedback to student, they may decide to give it another go with my new instructions."
      ],
      "metadata": {
        "id": "tCvNt_lKwT0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Challenge 2"
      ],
      "metadata": {
        "id": "olsaOvoSjUHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write code to plot a precision-versus-recall curve. Assume you have a binary list of true labels and a list of probabilities. puddles can help you."
      ],
      "metadata": {
        "id": "uVMtAhxVjW4L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "59zxUXqBjrOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Challenge 3\n",
        "\n",
        "Given a table, pull out column 'Outcome' and place it in a list."
      ],
      "metadata": {
        "id": "4ldAxYAzGXn7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o7MxwUr-Gipf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}